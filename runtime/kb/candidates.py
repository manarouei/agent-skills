#!/usr/bin/env python3
"""KB Promotion Candidate Schema.

This module defines the structured schema for promotion candidates
generated by the KB Maintenance Lane mining scripts.

Candidates are JSON files that can be reviewed and promoted to the KB
via scripts/promote_artifact.py.
"""

from __future__ import annotations

import hashlib
import json
import re
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from pathlib import Path
from typing import Any, Optional

# Import canonical categories from loader
from runtime.kb.loader import CANONICAL_CATEGORIES, normalize_category


class CandidateType(str, Enum):
    """Type of promotion candidate."""
    PATTERN = "pattern"
    FIX = "fix"


class SourceKind(str, Enum):
    """Kind of source evidence."""
    NODE_FILE = "node_file"
    CREDENTIAL_FILE = "credential_file"
    TRACE_MAP = "trace_map"
    FIX_LOOP = "fix_loop"
    ARTIFACT = "artifact"


@dataclass
class SourceReference:
    """Reference to a source of evidence."""
    kind: SourceKind
    path: str
    line_range: Optional[str] = None  # e.g., "L10-L25"
    correlation_id: Optional[str] = None
    excerpt_hash: Optional[str] = None

    def to_dict(self) -> dict[str, Any]:
        return {
            "kind": self.kind.value,
            "path": self.path,
            "line_range": self.line_range,
            "correlation_id": self.correlation_id,
            "excerpt_hash": self.excerpt_hash,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "SourceReference":
        return cls(
            kind=SourceKind(data["kind"]),
            path=data["path"],
            line_range=data.get("line_range"),
            correlation_id=data.get("correlation_id"),
            excerpt_hash=data.get("excerpt_hash"),
        )


@dataclass
class CandidateStats:
    """Statistics about candidate occurrence."""
    frequency: int = 1
    distinct_sources: int = 1
    first_seen: Optional[str] = None
    last_seen: Optional[str] = None

    def to_dict(self) -> dict[str, Any]:
        return {
            "frequency": self.frequency,
            "distinct_sources": self.distinct_sources,
            "first_seen": self.first_seen,
            "last_seen": self.last_seen,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "CandidateStats":
        return cls(
            frequency=data.get("frequency", 1),
            distinct_sources=data.get("distinct_sources", 1),
            first_seen=data.get("first_seen"),
            last_seen=data.get("last_seen"),
        )


@dataclass
class ReviewNotes:
    """Notes for human review."""
    risks: list[str] = field(default_factory=list)
    recommended_tests: list[str] = field(default_factory=list)
    promotion_target: Optional[str] = None  # Target KB file
    auto_promotable: bool = False  # True if meets threshold

    def to_dict(self) -> dict[str, Any]:
        return {
            "risks": self.risks,
            "recommended_tests": self.recommended_tests,
            "promotion_target": self.promotion_target,
            "auto_promotable": self.auto_promotable,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "ReviewNotes":
        return cls(
            risks=data.get("risks", []),
            recommended_tests=data.get("recommended_tests", []),
            promotion_target=data.get("promotion_target"),
            auto_promotable=data.get("auto_promotable", False),
        )


@dataclass
class MiningCandidate:
    """A structured candidate for KB promotion.
    
    This is the canonical schema for candidates generated by mining scripts.
    All fields are validated before serialization.
    """
    
    # Required identification
    candidate_id: str
    candidate_type: CandidateType
    category: str  # Must be canonical or normalizable
    title: str
    
    # Confidence and stats
    confidence: float  # 0.0 to 1.0
    stats: CandidateStats
    
    # Provenance
    provenance: list[SourceReference]
    
    # The actual pattern payload (must conform to KB schema)
    pattern: dict[str, Any]
    
    # Review metadata
    review_notes: ReviewNotes
    
    # Timestamps
    created_at: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    mining_run_id: Optional[str] = None

    def __post_init__(self) -> None:
        """Validate after initialization."""
        # Normalize category
        self.category = normalize_category(self.category)
        
        # Validate confidence range
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError(f"confidence must be 0.0-1.0, got {self.confidence}")
        
        # Validate candidate_id format
        if not re.match(r'^[a-z0-9_-]+$', self.candidate_id):
            raise ValueError(f"candidate_id must be lowercase alphanumeric with hyphens/underscores: {self.candidate_id}")

    def to_dict(self) -> dict[str, Any]:
        """Serialize to dictionary with stable key ordering."""
        return {
            "candidate_id": self.candidate_id,
            "candidate_type": self.candidate_type.value,
            "category": self.category,
            "title": self.title,
            "confidence": self.confidence,
            "stats": self.stats.to_dict(),
            "provenance": [p.to_dict() for p in self.provenance],
            "pattern": self.pattern,
            "review_notes": self.review_notes.to_dict(),
            "created_at": self.created_at,
            "mining_run_id": self.mining_run_id,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "MiningCandidate":
        """Deserialize from dictionary."""
        return cls(
            candidate_id=data["candidate_id"],
            candidate_type=CandidateType(data["candidate_type"]),
            category=data["category"],
            title=data["title"],
            confidence=data["confidence"],
            stats=CandidateStats.from_dict(data.get("stats", {})),
            provenance=[SourceReference.from_dict(p) for p in data.get("provenance", [])],
            pattern=data["pattern"],
            review_notes=ReviewNotes.from_dict(data.get("review_notes", {})),
            created_at=data.get("created_at", datetime.now(timezone.utc).isoformat()),
            mining_run_id=data.get("mining_run_id"),
        )

    def to_json(self, indent: int = 2) -> str:
        """Serialize to JSON with stable ordering."""
        return json.dumps(self.to_dict(), indent=indent, sort_keys=True)

    @classmethod
    def from_json(cls, json_str: str) -> "MiningCandidate":
        """Deserialize from JSON."""
        return cls.from_dict(json.loads(json_str))


@dataclass
class MiningRunManifest:
    """Manifest for a mining run."""
    run_id: str
    script_name: str
    inputs: list[str]
    timestamp: str
    git_commit: Optional[str] = None
    candidate_count: int = 0
    
    def to_dict(self) -> dict[str, Any]:
        return {
            "run_id": self.run_id,
            "script_name": self.script_name,
            "inputs": sorted(self.inputs),  # Stable ordering
            "timestamp": self.timestamp,
            "git_commit": self.git_commit,
            "candidate_count": self.candidate_count,
        }

    def to_json(self, indent: int = 2) -> str:
        return json.dumps(self.to_dict(), indent=indent, sort_keys=True)


def validate_candidate(candidate: MiningCandidate) -> list[str]:
    """Validate a candidate against requirements.
    
    Returns list of error messages (empty if valid).
    """
    errors = []
    
    # Check category is canonical
    if candidate.category not in CANONICAL_CATEGORIES:
        errors.append(f"Invalid category '{candidate.category}'. Must be one of: {sorted(CANONICAL_CATEGORIES)}")
    
    # Check required pattern fields based on category
    pattern = candidate.pattern
    if candidate.category == "auth":
        if pattern.get("type") != "auth":
            errors.append("Auth pattern must have type='auth'")
        if "auth_type" not in pattern:
            errors.append("Auth pattern must have 'auth_type' field")
    elif candidate.category == "pagination":
        if pattern.get("type") != "pagination":
            errors.append("Pagination pattern must have type='pagination'")
        if "style" not in pattern:
            errors.append("Pagination pattern must have 'style' field")
    elif candidate.category == "ts_to_python":
        if pattern.get("type") != "ts_to_python":
            errors.append("ts_to_python pattern must have type='ts_to_python'")
        if "ts_pattern" not in pattern or "python_pattern" not in pattern:
            errors.append("ts_to_python pattern must have 'ts_pattern' and 'python_pattern' fields")
    elif candidate.category == "service_quirk":
        if pattern.get("type") != "service_quirk":
            errors.append("service_quirk pattern must have type='service_quirk'")
        if "quirk_type" not in pattern:
            errors.append("service_quirk pattern must have 'quirk_type' field")
    
    # Check provenance is non-empty
    if not candidate.provenance:
        errors.append("Candidate must have at least one source reference in provenance")
    
    # Check stats
    if candidate.stats.frequency < 1:
        errors.append("Stats frequency must be >= 1")
    if candidate.stats.distinct_sources < 1:
        errors.append("Stats distinct_sources must be >= 1")
    
    return errors


def load_candidates_from_dir(candidates_dir: Path) -> list[MiningCandidate]:
    """Load all candidates from a directory.
    
    Raises ValidationError on first invalid candidate.
    """
    candidates = []
    for json_file in sorted(candidates_dir.glob("*.json")):
        if json_file.name == "manifest.json":
            continue
        data = json.loads(json_file.read_text())
        candidate = MiningCandidate.from_dict(data)
        errors = validate_candidate(candidate)
        if errors:
            raise ValueError(f"Invalid candidate {json_file.name}: {errors}")
        candidates.append(candidate)
    return candidates


def generate_candidate_id(category: str, fingerprint: str) -> str:
    """Generate a deterministic candidate ID from category and fingerprint."""
    h = hashlib.sha256(f"{category}:{fingerprint}".encode()).hexdigest()[:12]
    return f"{category}-{h}"
